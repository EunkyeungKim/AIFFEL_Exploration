{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edc3765c",
   "metadata": {},
   "source": [
    "회고\n",
    "\n",
    "1. 한글을 범위 지정할 수 있는 정규 표현식을 학습할 수 있었습니다.\n",
    "2. 참고한 코드를 따라 치고 주석을 달며 잘 몰랐던 코드를 공부하고 알고있던 코드에 대해서는 복습할 수 있었습니다.\n",
    "3. NLP분야의 데이터 전처리 과정을 잘 공부할 수 있었습니다.\n",
    "4. 라벨링 되지 않은 단어들도 있을텐데 그런 단어를 입력 받았을 때 부정 긍정을 어떤 기준에 의거해 판단했는지가 궁금해졌고 생각보다 이상한 말들도 잘 맞춰서 관심이 없던 NLP인데 조금 관심이 생겼습니다.\n",
    "5. ('ㅜㅜ' 여부로 긍정 부정이 나뉘는게 넘 신기하다. 울면 부정이라고 할 수 있을것 같은데 긍정이다. 감동 감정으로 판단했나보다. 영화 리뷰에서는 영화가 별로면 울지 않고 욕을 해서 그런가? 그러면 챗봇에 사용되는 데이터들은 좀 라벨링이 다르게 될 수도 있겠다. 같은 말이라고 해서 또 라벨을 어떻게 붙이냐가 중요한 요인이 될 수 있겠구나 생각했다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1268951a",
   "metadata": {},
   "source": [
    "1) 데이터 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c312128",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request   # urllib — URL 처리 모듈\n",
    "from konlpy.tag import Okt  # 코엔엘파이(KoNLPy) 한글 형태소 분석을 지원하는 라이브러리\n",
    "from tqdm import tqdm  # tqdm - python 진행 프로세스바\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 1) 데이터 로드하기\n",
    "\n",
    "train_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sentiment_classification/data/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7442672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 리뷰 개수 : 150000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('훈련용 리뷰 개수 :',len(train_data)) # 훈련용 리뷰 개수 출력\n",
    "train_data[:5] # 상위 5개 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74662f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트용 리뷰 개수 : 50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('테스트용 리뷰 개수 :',len(test_data)) # 테스트용 리뷰 개수 출력\n",
    "test_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba817c1",
   "metadata": {},
   "source": [
    "2) 데이터 정제하기\n",
    "\n",
    "train_data의 데이터 중복 유무를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d54b011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146182, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# document 열과 label 열의 중복을 제외한 값의 개수\n",
    "train_data['document'].nunique(), train_data['label'].nunique() # nunique()는 데이터에 고유값들의 수를 출력해주는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf6caad",
   "metadata": {},
   "source": [
    "총 150,000개의 샘플이 존재하는데 document열에서 중복을 제거한 샘플의 개수가 146,182개라는 것은 약 4,000개의 중복 샘플이 존재한다는 의미입니다. label 열은 0 또는 1의 두 가지 값만을 가지므로 2가 출력됩니다. 중복 샘플을 제거합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd60e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_duplicates 메서드를 이용해 document 열의 중복 제거\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fbdfe2",
   "metadata": {},
   "source": [
    "중복 샘플을 제거하였습니다. 중복이 제거되었는지 전체 샘플 수를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1608681a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 수 : 146183\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 수 :',len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0ad92f",
   "metadata": {},
   "source": [
    "중복 샘플이 제거되었습니다. train_data에서 해당 리뷰의 긍, 부정 유무가 기재되어있는 레이블(label) 값의 분포를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75159de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data['label'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a54081",
   "metadata": {},
   "source": [
    "앞서 확인하였듯이 약 146,000개의 영화 리뷰 샘플이 존재하는데 그래프 상으로 긍정과 부정 둘 다 약 72,000개의 샘플이 존재하여 레이블의 분포가 균일한 것처럼 보입니다. 정확하게 몇 개인지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d011562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  count\n",
      "0      0  73342\n",
      "1      1  72841\n"
     ]
    }
   ],
   "source": [
    "# groupby() 연산자를 사용하여 집단, 그룹별로 데이터를 집계, 요약\n",
    "print(train_data.groupby('label').size().reset_index(name = 'count')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabfad47",
   "metadata": {},
   "source": [
    "레이블이 0인 리뷰가 근소하게 많습니다. 리뷰 중에 Null 값을 가진 샘플이 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527361c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# df.isnull().values는 데이터 프레임의 NumPy 표현을 반환합니다. numpy.any()는 요소 중 하나라도 True으로 평가되면 True을 반환합니다.\n",
    "print(train_data.isnull().values.any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f99b4",
   "metadata": {},
   "source": [
    "True가 나왔다면 데이터 중에 Null 값을 가진 샘플이 존재한다는 의미입니다. 어떤 열에 존재하는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db43ba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 칼럼별 결측값 개수 구하기 : df.isnull().sum()\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb7612",
   "metadata": {},
   "source": [
    "리뷰가 적혀있는 document 열에서 Null 값을 가진 샘플이 총 1개가 존재한다고 합니다. 그렇다면 document 열에서 Null 값이 존재한다는 것을 조건으로 Null 값을 가진 샘플이 어느 인덱스의 위치에 존재하는지 한 번 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef9897aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25857</th>\n",
       "      <td>2172111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id document  label\n",
       "25857  2172111      NaN      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[train_data.document.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b25ff7c",
   "metadata": {},
   "source": [
    "출력 결과는 위와 같습니다. Null 값을 가진 샘플을 제거하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c35270b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna(how = 'any') # Null 값이 존재하는 행 제거\n",
    "print(train_data.isnull().values.any()) # Null 값이 존재하는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac93d31",
   "metadata": {},
   "source": [
    "Null 값을 가진 샘플이 제거되었습니다. 다시 샘플의 개수를 출력하여 1개의 샘플이 제거되었는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a704434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146182\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45437ea",
   "metadata": {},
   "source": [
    "위의 train_data와 test_data에서 온점(.)이나 ?와 같은 각종 특수문자가 사용된 것을 확인했습니다. train_data로부터 한글만 남기고 제거하기 위해서 정규 표현식을 사용해보겠습니다.\n",
    "\n",
    "우선 영어를 예시로 정규 표현식을 설명해보겠습니다. 영어의 알파벳들을 나타내는 정규 표현식은 [a-zA-Z]입니다. 이 정규 표현식은 영어의 소문자와 대문자들을 모두 포함하고 있는 정규 표현식으로 이를 응용하면 영어에 속하지 않는 구두점이나 특수문자를 제거할 수 있습니다. 예를 들어 알파벳과 공백을 제외하고 모두 제거하는 전처리를 수행하는 예제는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec621119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you expect people to read the FAQ etc and actually accept hard atheism\n"
     ]
    }
   ],
   "source": [
    "#알파벳과 공백을 제외하고 모두 제거\n",
    "eng_text = 'do!!! you expect... people~ to~ read~ the FAQ, etc. and actually accept hard~! atheism?@@'\n",
    "print(re.sub(r'[^a-zA-Z ]', '', eng_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9caa38",
   "metadata": {},
   "source": [
    "위와 같은 원리를 한국어 데이터에 적용하고 싶다면, 우선 한글을 범위 지정할 수 있는 정규 표현식을 찾아내면 되겠습니다. 우선 자음과 모음에 대한 범위를 지정해보겠습니다. 일반적으로 자음의 범위는 ㄱ ~ ㅎ, 모음의 범위는 ㅏ ~ ㅣ와 같이 지정할 수 있습니다. \n",
    "\n",
    "ㄱ ~ ㅎ: 3131 ~ 314E\n",
    "ㅏ ~ ㅣ: 314F ~ 3163\n",
    "\n",
    "완성형 한글의 범위는 가 ~ 힣과 같이 사용합니다.\n",
    "\n",
    "위 범위 지정을 모두 반영하여 train_data에 한글과 공백을 제외하고 모두 제거하는 정규 표현식을 수행해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e8016c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/3525229848.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 한글과 공백을 제외하고 모두 제거\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bafcf9",
   "metadata": {},
   "source": [
    "상위 5개의 샘플을 다시 출력해보았는데, 정규 표현식을 수행하자 기존의 공백. 즉, 띄어쓰기는 유지되면서 온점과 같은 구두점 등은 제거되었습니다. 사실 네이버 영화 리뷰는 한글이 아니더라도 영어, 숫자, 특수문자로도 리뷰를 업로드할 수 있습니다. 다시 말해 기존에 한글이 없는 리뷰였다면 더 이상 아무런 값도 없는 빈(empty) 값이 되었을 것입니다. train_data에 공백(whitespace)만 있거나 빈 값을 가진 행이 있다면 Null 값으로 변경하도록 하고, Null 값이 존재하는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7c79a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "document    789\n",
      "label         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/2260017223.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n"
     ]
    }
   ],
   "source": [
    "train_data['document'] = train_data['document'].str.replace('^ +', \"\") # white space 데이터를 empty value로 변경\n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db982f6",
   "metadata": {},
   "source": [
    "Null 값이 789개나 새로 생겼습니다. Null 값이 있는 행을 5개만 출력해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d71e6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>4221289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>9509970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>10147571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>7117896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>6478189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id document  label\n",
       "404   4221289      NaN      0\n",
       "412   9509970      NaN      1\n",
       "470  10147571      NaN      1\n",
       "584   7117896      NaN      0\n",
       "593   6478189      NaN      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.loc[train_data.document.isnull()][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4234b6",
   "metadata": {},
   "source": [
    "Null 샘플들은 레이블이 긍정일 수도 있고, 부정일 수도 있습니다. 아무런 의미도 없는 데이터므로 제거해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f69bcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145393\n"
     ]
    }
   ],
   "source": [
    "train_data = train_data.dropna(how = 'any')\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8715a2",
   "metadata": {},
   "source": [
    "샘플 개수가 또 다시 줄어서 145,393개가 남았습니다. 테스트 데이터에 앞서 진행한 전처리 과정을 동일하게 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b9f3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후 테스트용 샘플의 개수 : 48852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13/869464319.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
      "/tmp/ipykernel_13/869464319.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n"
     ]
    }
   ],
   "source": [
    "test_data.drop_duplicates(subset = ['document'], inplace=True) # drop_duplicates는 document 열에서 중복인 내용이 있다면 삭제\n",
    "test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\") # 정규 표현식 수행\n",
    "test_data['document'] = test_data['document'].str.replace('^ +', \"\") # 공백은 empty 값으로 변경\n",
    "test_data['document'].replace('', np.nan, inplace=True) # 공백은 Null 값으로 변경\n",
    "test_data = test_data.dropna(how='any') # Null 값 제거\n",
    "print('전처리 후 테스트용 샘플의 개수 :',len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084f4c2d",
   "metadata": {},
   "source": [
    "3) 토큰화\n",
    "\n",
    "토큰화를 진행해봅시다. 토큰화 과정에서 불용어를 제거하겠습니다. 불용어는 정의하기 나름인데, 한국어의 조사, 접속사 등의 보편적인 불용어를 사용할 수도 있겠지만 결국 풀고자 하는 문제의 데이터를 지속 검토하면서 계속해서 추가하는 경우 또한 많습니다. 실제 현업인 상황이라면 일반적으로 아래의 불용어보다 더 많은 불용어를 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f72c8d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e40d6d9",
   "metadata": {},
   "source": [
    "여기서는 위 정도로만 불용어를 정의하고, 토큰화를 위한 형태소 분석기는 KoNLPy의 Okt를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d493c3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['오다', '이렇다', '것', '도', '영화', '라고', '차라리', '뮤직비디오', '를', '만들다', '게', '나다', '뻔']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt = Okt()\n",
    "okt.morphs('와 이런 것도 영화라고 차라리 뮤직비디오를 만드는 게 나을 뻔', stem = True) # 텍스트를 형태소 단위로 나눈다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25badc45",
   "metadata": {},
   "source": [
    "Okt는 위와 같이 KoNLPy에서 제공하는 형태소 분석기입니다. 한국어을 토큰화할 때는 영어처럼 띄어쓰기 기준으로 토큰화를 하는 것이 아니라, 주로 형태소 분석기를 사용한다고 언급한 바 있습니다. stem = True를 사용하면 일정 수준의 정규화를 수행해주는데, 예를 들어 위의 예제의 결과를 보면 '이런'이 '이렇다'로 변환되었고 '만드는'이 '만들다'로 변환된 것을 알 수 있습니다. train_data에 형태소 분석기를 사용하여 토큰화를 하면서 불용어를 제거하여 X_train에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaa7bcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145393/145393 [04:23<00:00, 551.66it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    X_train.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a6a4d",
   "metadata": {},
   "source": [
    "상위 3개의 샘플만 출력하여 결과를 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba0ccbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['아', '더빙', '진짜', '짜증나다', '목소리'], ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다'], ['너', '무재', '밓었', '다그', '래서', '보다', '추천', '다']]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607bbca",
   "metadata": {},
   "source": [
    "형태소 토큰화가 진행된 것을 볼 수 있습니다. 테스트 데이터에 대해서도 동일하게 토큰화를 해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "138ef70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48852/48852 [01:28<00:00, 553.82it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "for sentence in tqdm(test_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    X_test.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a26697",
   "metadata": {},
   "source": [
    "지금까지 훈련 데이터와 테스트 데이터에 대해서 텍스트 전처리를 진행해보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd49062",
   "metadata": {},
   "source": [
    "4) 정수 인코딩\n",
    "\n",
    "기계가 텍스트를 숫자로 처리할 수 있도록 훈련 데이터와 테스트 데이터에 정수 인코딩을 수행해야 합니다. 우선, 훈련 데이터에 대해서 단어 집합(vocaburary)을 만들어봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8940937",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68cc9129",
   "metadata": {},
   "source": [
    "단어 집합이 생성되는 동시에 각 단어에 고유한 정수가 부여되었습니다. 이는 tokenizer.word_index를 출력하여 확인 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d0cc4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tokenizer.word_index) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5388ad1",
   "metadata": {},
   "source": [
    "단어가 43,000개가 넘게 존재합니다. 각 정수는 전체 훈련 데이터에서 등장 빈도수가 높은 순서대로 부여되었기 때문에, 높은 정수가 부여된 단어들은 등장 빈도수가 매우 낮다는 것을 의미합니다. 여기서는 빈도수가 낮은 단어들은 자연어 처리에서 배제하고자 합니다. 등장 빈도수가 3회 미만인 단어들이 이 데이터에서 얼만큼의 비중을 차지하는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bcead84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 43752\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 24337\n",
      "단어 집합에서 희귀 단어의 비율: 55.62488571950996\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.8715872104872904\n"
     ]
    }
   ],
   "source": [
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0691211",
   "metadata": {},
   "source": [
    "등장 빈도가 threshold 값인 3회 미만. 즉, 2회 이하인 단어들은 단어 집합에서 무려 절반 이상을 차지합니다. 하지만, 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 매우 적은 수치인 1.87%밖에 되지 않습니다. 아무래도 등장 빈도가 2회 이하인 단어들은 자연어 처리에서 별로 중요하지 않을 듯 합니다. 그래서 이 단어들은 정수 인코딩 과정에서 배제시키겠습니다.\n",
    "\n",
    "등장 빈도수가 2이하인 단어들의 수를 제외한 단어의 개수를 단어 집합의 최대 크기로 제한하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21d60e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 19416\n"
     ]
    }
   ],
   "source": [
    "# 전체 단어 개수 중 빈도수 2이하인 단어는 제거.\n",
    "# 0번 패딩 토큰을 고려하여 + 1\n",
    "vocab_size = total_cnt - rare_cnt + 1\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bc9796",
   "metadata": {},
   "source": [
    "단어 집합의 크기는 19,416개입니다. 이를 케라스 토크나이저의 인자로 넘겨주고 텍스트 시퀀스를 정수 시퀀스로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ceaef507",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793e4aa9",
   "metadata": {},
   "source": [
    "정수 인코딩이 진행되었는지 확인하고자 X_train에 대해서 상위 3개의 샘플만 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59c48299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[50, 454, 16, 260, 659], [933, 457, 41, 602, 1, 214, 1449, 24, 961, 675, 19], [386, 2444, 2315, 5671, 2, 222, 9]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33db468",
   "metadata": {},
   "source": [
    "각 샘플 내의 단어들은 각 단어에 대한 정수로 변환된 것을 확인할 수 있습니다. 단어의 개수는 19,416개로 제한되었으므로 0번 단어 ~ 19,415번 단어까지만 사용 중입니다. 0번 단어는 패딩을 위한 토큰임을 상기합시다. train_data에서 y_train과 y_test를 별도로 저장해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88118e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_data['label'])\n",
    "y_test = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b147fe7d",
   "metadata": {},
   "source": [
    "5) 빈 샘플(empty samples) 제거\n",
    "\n",
    "전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 빈(empty) 샘플이 되었다는 것을 의미합니다. 빈 샘플들은 어떤 레이블이 붙어있던 의미가 없으므로 빈 샘플들을 제거해주는 작업을 하겠습니다. 각 샘플들의 길이를 확인해서 길이가 0인 샘플들의 인덱스를 받아오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1283dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in enumerate(t): 반복문 사용 시 몇 번째 반복문인지 확인이 필요할 수 있습니다. 인덱스 번호와 컬렉션의 원소를 tuple형태로 반환합니다\n",
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb48f61b",
   "metadata": {},
   "source": [
    "drop_train에는 X_train으로부터 얻은 빈 샘플들의 인덱스가 저장됩니다. 앞서 훈련 데이터(X_train, y_train)의 샘플 개수는 145,791개임을 확인했었습니다. 그렇다면 빈 샘플들을 제거한 후의 샘플 개수는 몇 개일까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ea8b802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145162\n",
      "145162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/numpy/lib/function_base.py:4454: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = asarray(arr)\n"
     ]
    }
   ],
   "source": [
    "# 빈 샘플들을 제거\n",
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "print(len(X_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee804ae7",
   "metadata": {},
   "source": [
    "145,162개로 샘플의 수가 줄어든 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d12f1",
   "metadata": {},
   "source": [
    "6) 패딩\n",
    "\n",
    "서로 다른 길이의 샘플들의 길이를 동일하게 맞춰주는 패딩 작업을 진행해보겠습니다. 전체 데이터에서 가장 길이가 긴 리뷰와 전체 데이터의 길이 분포를 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49ed1597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰의 최대 길이 : 69\n",
      "리뷰의 평균 길이 : 10.812485361182679\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('리뷰의 최대 길이 :',max(len(review) for review in X_train))\n",
    "print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(review) for review in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ed1bf3",
   "metadata": {},
   "source": [
    "가장 긴 리뷰의 길이는 69이며, 그래프를 봤을 때 전체 데이터의 길이 분포는 대체적으로 약 11내외의 길이를 가지는 것을 볼 수 있습니다. 모델이 처리할 수 있도록 X_train과 X_test의 모든 샘플의 길이를 특정 길이로 동일하게 맞춰줄 필요가 있습니다. 특정 길이 변수를 max_len으로 정합니다. 대부분의 리뷰가 내용이 잘리지 않도록 할 수 있는 최적의 max_len의 값은 몇일까요? 전체 샘플 중 길이가 max_len 이하인 샘플의 비율이 몇 %인지 확인하는 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c16d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  count = 0\n",
    "  for sentence in nested_list:\n",
    "    if(len(sentence) <= max_len):\n",
    "        count = count + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (count / len(nested_list))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf1f9d6",
   "metadata": {},
   "source": [
    "위의 분포 그래프를 봤을 때, max_len = 30이 적당할 것 같습니다. 이 값이 얼마나 많은 리뷰 길이를 커버하는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d76be4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 30 이하인 샘플의 비율: 94.31944999380003\n"
     ]
    }
   ],
   "source": [
    "max_len = 30\n",
    "below_threshold_len(max_len, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0fe5db",
   "metadata": {},
   "source": [
    "전체 훈련 데이터 중 약 94%의 리뷰가 30이하의 길이를 가지는 것을 확인했습니다. 모든 샘플의 길이를 30으로 맞추겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a260c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f3ef63",
   "metadata": {},
   "source": [
    "2. LSTM으로 네이버 영화 리뷰 감성 분류하기\n",
    "\n",
    "하이퍼파라미터인 임베딩 벡터의 차원은 100, 은닉 상태의 크기는 128입니다. 모델은 다 대 일 구조의 LSTM을 사용합니다. 해당 모델은 마지막 시점에서 두 개의 선택지 중 하나를 예측하는 이진 분류 문제를 수행하는 모델입니다. 이진 분류 문제의 경우, 출력층에 로지스틱 회귀를 사용해야 하므로 활성화 함수로는 시그모이드 함수를 사용하고, 손실 함수로 크로스 엔트로피 함수를 사용합니다. 하이퍼파라미터인 배치 크기는 64이며, 15 에포크를 수행합니다.\n",
    "\n",
    "EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)는 검증 데이터 손실(val_loss)이 증가하면, 과적합 징후므로 검증 데이터 손실이 4회 증가하면 정해진 에포크가 도달하지 못하였더라도 학습을 조기 종료(Early Stopping)한다는 의미입니다. ModelCheckpoint를 사용하여 검증 데이터의 정확도(val_acc)가 이전보다 좋아질 경우에만 모델을 저장합니다. validation_split=0.2을 사용하여 훈련 데이터의 20%를 검증 데이터로 분리해서 사용하고, 검증 데이터를 통해서 훈련이 적절히 되고 있는지 확인합니다. 검증 데이터는 기계가 훈련 데이터에 과적합되고 있지는 않은지 확인하기 위한 용도로 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0208939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1815/1815 [==============================] - 15s 6ms/step - loss: 0.3890 - acc: 0.8230 - val_loss: 0.3515 - val_acc: 0.8445\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.84452, saving model to best_model.h5\n",
      "Epoch 2/15\n",
      "1815/1815 [==============================] - 10s 5ms/step - loss: 0.3267 - acc: 0.8581 - val_loss: 0.3332 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.84452 to 0.85592, saving model to best_model.h5\n",
      "Epoch 3/15\n",
      "1815/1815 [==============================] - 10s 5ms/step - loss: 0.3013 - acc: 0.8722 - val_loss: 0.3289 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.85592 to 0.85709, saving model to best_model.h5\n",
      "Epoch 4/15\n",
      "1815/1815 [==============================] - 10s 5ms/step - loss: 0.2830 - acc: 0.8827 - val_loss: 0.3267 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.85709 to 0.86002, saving model to best_model.h5\n",
      "Epoch 5/15\n",
      "1815/1815 [==============================] - 10s 5ms/step - loss: 0.2669 - acc: 0.8911 - val_loss: 0.3338 - val_acc: 0.8577\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.86002\n",
      "Epoch 6/15\n",
      "1815/1815 [==============================] - 10s 5ms/step - loss: 0.2508 - acc: 0.8981 - val_loss: 0.3365 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.86002\n",
      "Epoch 7/15\n",
      "1815/1815 [==============================] - 10s 5ms/step - loss: 0.2349 - acc: 0.9063 - val_loss: 0.3482 - val_acc: 0.8542\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.86002\n",
      "Epoch 8/15\n",
      "1815/1815 [==============================] - 10s 5ms/step - loss: 0.2197 - acc: 0.9133 - val_loss: 0.3525 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.86002\n",
      "Epoch 00008: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_units = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_dim))\n",
    "model.add(LSTM(hidden_units))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ec2a1c",
   "metadata": {},
   "source": [
    "저자의 경우 조기 종료 조건에 따라서 9 에포크에서 훈련이 멈췄습니다. 훈련이 다 되었다면 테스트 데이터에 대해서 정확도를 측정할 차례입니다. 훈련 과정에서 검증 데이터의 정확도가 가장 높았을 때 저장된 모델인 'best_model.h5'를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b6d3832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1527/1527 [==============================] - 4s 2ms/step - loss: 0.3349 - acc: 0.8558\n",
      "\n",
      " 테스트 정확도: 0.8558\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('best_model.h5')\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9de20d2",
   "metadata": {},
   "source": [
    "테스트 데이터에서 85.71%의 정확도를 얻습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d60afa1",
   "metadata": {},
   "source": [
    "3. 리뷰 예측해보기\n",
    "\n",
    "임의의 리뷰에 대해서 예측하는 함수를 만들어보겠습니다. 기본적으로 현재 학습한 model에 새로운 입력에 대해서 예측값을 얻는 것은 model.predict()를 사용합니다. 그리고 model.fit()을 할 때와 마찬가지로 새로운 입력에 대해서도 동일한 전처리를 수행 후에 model.predict()의 입력으로 사용해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d926b107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "  new_sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣 ]','', new_sentence)\n",
    "  new_sentence = okt.morphs(new_sentence, stem=True) # 토큰화\n",
    "  new_sentence = [word for word in new_sentence if not word in stopwords] # 불용어 제거\n",
    "  encoded = tokenizer.texts_to_sequences([new_sentence]) # 정수 인코딩\n",
    "  pad_new = pad_sequences(encoded, maxlen = max_len) # 패딩\n",
    "  score = float(loaded_model.predict(pad_new)) # 예측\n",
    "  if(score > 0.5):\n",
    "    print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(score * 100))\n",
    "  else:\n",
    "    print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - score) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "27236459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.08% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('와 개쩐다 정말 세계관 최강자들의 영화다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e436f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.91% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('미쳤다 존잼')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "165f6210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.19% 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('이런 영화는 난생 처음. 잠만잤음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5773a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.55% 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('감독은 바보냐')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13277dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.60% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('기억에 많이 남을것 같은 엔딩')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "53ea0e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.60% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('배우들 연기 굿. 스토리 사실감 넘침.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec0bc6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.99% 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('틀딱 잼민이들 많았음. ') # 이런것도 분류가 된다고? ㅋㅋㅋㅋ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "92ca4c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.41% 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('슉슈슈슉 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6eb2da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.41% 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('쿠쿠루삥뽕 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f013cfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.55% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('하...ㅜㅜ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5fbfb575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.13% 확률로 부정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('하...')  # ㅋㅋㅋㅋ 신기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df8cae7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.84% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentiment_predict('막걸리에 파전이 생각나는 영화') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be686a0",
   "metadata": {},
   "source": [
    "참고자료 \n",
    "\n",
    "https://wikidocs.net/44249\n",
    "\n",
    "https://kongdols-room.tistory.com/124\n",
    "\n",
    "https://cceeddcc.tistory.com/8\n",
    "\n",
    "https://docs.python.org/ko/3/library/urllib.html\n",
    "\n",
    "https://skillmemory.tistory.com/entry/tqdm-%EC%82%AC%EC%9A%A9%EB%B2%95-python-%EC%A7%84%ED%96%89%EB%A5%A0-%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4%EB%B0%94\n",
    "\n",
    "https://jaaamj.tistory.com/112\n",
    "\n",
    "https://rfriend.tistory.com/383\n",
    "\n",
    "https://www.delftstack.com/ko/howto/python-pandas/how-to-check-if-nan-exisits-in-pandas-dataframe/\n",
    "\n",
    "https://truman.tistory.com/112"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
